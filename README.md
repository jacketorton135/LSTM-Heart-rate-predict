# 蔣駿杰的˙LSTM-Heart-rate-predict

 深度學習的過程包含兩階段：訓練階段和預測階段，在訓練前我們會將資
料分成訓練集與測試集，將訓練集丟入建置的深度神經網路，進行資料的特徵
擷取，並且產生預期輸出，用於計算訓練誤差，再透過學習演算法重新調整參
數，進行多次迭代的學習，直到代價函數收斂；預測階段時，將測試集丟入訓
練過後的神經網路，由於測試集的資料是未曾訓練過的，並不知道會產生甚麼11 
 
輸出結果，而網路會對資料做特徵擷取，網路中調整過的權重會將輸入資料 
映射出一個輸出結果，即整個網路的預測結果。

 ![image](https://github.com/user-attachments/assets/d973e895-3fe4-41b1-bfed-9e4fbfefbfa9)

 ![image](https://github.com/user-attachments/assets/5942dc48-3422-49bb-95e4-ed4d4872e72e)



 根據程式碼中的 k 折交叉驗證（StratifiedKFold）設定，詳細解釋驗證集的特點和交叉驗證的功用：
交叉驗證設置：

使用 StratifiedKFold，將資料分為 5 折（n_splits=5）
每一折中，訓練集佔 80%，驗證集佔 20%
使用分層抽樣（Stratified），確保每一折中各類別（有/無心臟病）的比例與原始資料集一致

交叉驗證的主要功用：

更可靠的性能評估：


不是只用一次劃分來評估模型
每個樣本都會被用於驗證一次
可以減少因資料劃分不均勻導致的偏差


樣本利用：


每個樣本都會被用於模型訓練和驗證
充分利用有限的數據集


提高模型泛化能力：


多次在不同資料子集上訓練和驗證
幫助模型學習更穩定、更具代表性的特徵


原始資料集總計：303筆

有心臟病 (1)：165筆
無心臟病 (0)：138筆

使用 5 折交叉驗證（StratifiedKFold）：
每一折(20%驗證集, 80%訓練集)：

驗證集：

總計：約 61筆
有心臟病：約 33筆 (165 * 0.2)
無心臟病：約 28筆 (138 * 0.2)


訓練集：

總計：約 242筆
有心臟病：約 132筆 (165 * 0.8)
無心臟病：約 110筆 (138 * 0.8)



特點：

每一折都保持原始數據的類別比例
所有樣本在 5 次交叉驗證中都會被用於訓練和驗證
沒有單獨的測試集，驗證集的角色類似於傳統的測試集

![Figure_準確](https://github.com/user-attachments/assets/94e6248d-851a-45dc-9e62-0c4e8e364754)

混淆矩陣

內容：

混淆矩陣顯示了模型對樣本的分類結果。
橫軸：預測的標籤（"無心臟病" 和 "有心臟病"）。
縱軸：實際的標籤（"無心臟病" 和 "有心臟病"）。
數字代表樣本的數量。
數據：

22（左上）：模型正確地預測為 "無心臟病" 的樣本數（真陰性）。
6（右上）：模型錯誤地預測為 "有心臟病" 的樣本數（假陽性）。
6（左下）：模型錯誤地預測為 "無心臟病" 的樣本數（假陰性）。
27（右下）：模型正確地預測為 "有心臟病" 的樣本數（真陽性）。
分析：

模型總體的分類效果不錯，真陽性和真陰性數量較高。
假陽性和假陰性數量相對較低，但還有改進空間。

混淆矩陣是一種用於評估分類模型性能的工具，顯示了模型預測結果與實際標籤之間的對比。以下是矩陣的結構及其解釋：

預測：無心臟病	預測：有心臟病
實際：無心臟病	真陰性 (TN) = 22	假陽性 (FP) = 6
實際：有心臟病	假陰性 (FN) = 6	真陽性 (TP) = 27

![image](https://github.com/user-attachments/assets/3669e34c-5ea3-421d-88e9-5ba6fc8e22d8)


第一張圖（混淆矩陣）：

模型分類效果不錯，但假陽性和假陰性依然存在，需要進一步提升分類能力。

![曲線_1](https://github.com/user-attachments/assets/579e0493-d96c-44f9-9827-aa31288c4e8e)


模型的學習曲線

 模型損失曲線
X軸：Epoch（訓練的迭代次數）。
Y軸：Loss（損失值）。
曲線描述：
藍線：訓練損失。
橙線：驗證損失。
分析：
訓練損失和驗證損失均呈現下降趨勢，表明模型在逐步學習數據特徵。
驗證損失下降速度快於訓練損失，且持續下降至最後，顯示模型對測試數據的泛化能力較好。
若驗證損失明顯高於訓練損失，則可能出現過擬合，但此圖表未顯示出這種情況。
(右上) 模型準確率曲線
X軸：Epoch（訓練的迭代次數）。
Y軸：Accuracy（準確率）。
曲線描述：
藍線：訓練準確率。
橙線：驗證準確率。
分析：
訓練準確率隨 Epoch 增加而穩定上升，說明模型逐漸學會數據中的模式。
驗證準確率從一開始迅速提高，並保持穩定在 ~80%，顯示模型在驗證數據上的表現良好，沒有明顯的過擬合。
橙線（驗證準確率）優於藍線（訓練準確率），可能是因為訓練數據包含更多樣性樣本。
(左下) 模型 AUC 曲線
X軸：Epoch（訓練的迭代次數）。
Y軸：AUC（ROC 曲線下面積）。
曲線描述：
藍線：訓練 AUC。
橙線：驗證 AUC。
分析：
AUC 表示分類器的整體性能，數值越接近 1，模型性能越好。
訓練 AUC 緩慢增長並趨於穩定，驗證 AUC 則持續增長，最終接近 0.9，顯示模型在驗證數據上的分類能力非常好。
橙線始終高於藍線，說明模型在驗證集上的表現優於訓練集，沒有過度依賴訓練數據。

第二張圖（學習曲線）：

模型訓練和驗證損失均穩定下降，驗證損失低於訓練損失，表現出良好的學習能力和泛化性能。
準確率和 AUC 均持續提升，驗證準確率達到 80%，AUC 接近 0.9，顯示模型分類性能優秀。
沒有出現過擬合跡象，但仍可以進一步優化（如調參或增加數據量）。

特徵

![image](https://github.com/user-attachments/assets/f66e04f1-f200-4095-8e8d-049e646b2540)

長短期記憶（LSTM）
LSTM 的理論基礎理論受到循環神經網路（RNN）的學習輸出的影響。 RNN 是一種用於處理有關序列的資料的神經網路。 Hochreiter 提出的 LSTM 方法有潛力學習變數之間的長依賴關係。長期時間序列是使用 LSTM 演算法計算的。面對長時間的時間序列結果，它可以極大地促進神經網路演算法的梯度爆炸和梯度消失

 LSTM 單元安裝了三個門，分別是輸入門、遺忘門和輸出門。它們專門用於決定保留哪些資訊。透過切換門，LSTM 網路應用臨時記憶體來避免梯度消失。


![image](https://github.com/user-attachments/assets/1edb5445-2fb0-479f-abc2-68ee06521c13)

結合前端app
![image](https://github.com/user-attachments/assets/b3251131-c4ed-4185-a2d8-ebb850e80cfb)

![image](https://github.com/user-attachments/assets/95c9f151-0853-4457-9016-8e2923190d86)

![image](https://github.com/user-attachments/assets/3880face-8a22-4ae4-95ba-38d584198ce1)

![image](https://github.com/user-attachments/assets/616a002e-9e42-4a20-86dd-97c8787d73db)








